#To comment a block of code select and ctr+shift+c
library(tidyverse)  # data manipulation
library(factoextra) # clustering algorithms & visualization and for gap_stats
library(cluster)    # clustering algorithms
library(e1071)
library(gridExtra)   #for qplot or to check normal distribution
library(caret)
library(fBasics)
library(dplyr)
library(plyr)
require(ggplot2)
require(reshape2)
library(VGAM)
library(corrplot)
# K-means algorithm analysis
hdata<-read.csv('ethereum.csv')   #hburg,ethereum,mios,piet
horg<-read.csv("ethereum.csv")
hdataorg<-read.csv("ethereum.csv")
str(hdata)
hdata_corrmatrix <- cor(horg)
write.csv(hdata_corrmatrix,"hdata_corrmatrix.csv")
pdf("hdata_corrmatrix.pdf")
corrplot(hdata_corrmatrix, method = 'number')
dev.off()
pdf("bp_hdata.pdf")
boxplot(hdata, ylim=c(0,60), boxwex = 0.5)
dev.off()
hdata_basic_stats<-basicStats(hdata)
write.csv(hdata_basic_stats,'hdata_basic_stats.csv')
hdata1<-hdata+1
hdata_log<-hdata1
hdata_log$ind<-log(hdata_log$ind)
hdata_log$outd<-log(hdata_log$outd)
hdata_log$cc<-log(hdata_log$cc)
hdata_log$ts<-log(hdata_log$ts)
hdata_log$bd<-log(hdata_log$bd)
hdata_log$loc<-log(hdata_log$loc)
hdata_log_basic_stats<-basicStats(hdata_log)
write.csv(hdata_log_basic_stats,'hdata_log_basic_stats.csv')
getmode<-function(x){
uniq<-unique(x)
uniq[which.max(tabulate(match(x,uniq)))]
}
hdata_log_mean<- colMeans(hdata_log)
hdata_log_mean
hdata_log_median<- apply(hdata_log,2,median)  #2 is margin means col, sd is function
hdata_log_median
hdata_log_mode<- apply(hdata_log,2,getmode)  #2 is margin means col, sd is function
hdata_log_mode
hdata_log_sd<- apply(hdata_log,2,sd)  #2 is margin means col, sd is function
hdata_log_sd
hdata_log_th_outd<-hdata_log_mean[2]+hdata_log_sd[2]
hdata_log_th_acc<-hdata_log_mean[3]+hdata_log_sd[3]
hdata_log_th_ts<-hdata_log_mean[4]+hdata_log_sd[4]
hdata_log_th_loc<-hdata_log_mean[6]+hdata_log_sd[6]
hdata_log_thr<- matrix(c(hdata_log_th_ind, hdata_log_th_outd,hdata_log_th_acc,hdata_log_th_ts,hdata_log_th_branch, hdata_log_th_loc))
# now calculate threshold of each  metric for the logrithmic value of metrics given metric values th=exp(T'), T'=mean+sd
hdata_log_th_ind<-hdata_log_mean[1]+hdata_log_sd[1]
hdata_log_thr<-as.table(hdata_log_thr)
hdata_log_thr
hdata_log_th_branch<-hdata_log_mean[5]+hdata_log_sd[5]
hdata_log_stats<-matrix(c(hdata_log_mean, hdata_log_median, hdata_log_mode,  hdata_log_thr, hdata_log_sd),ncol = 6, byrow = TRUE)
colnames(hdata_log_stats)<-c('ind','outd','acc','ts','branch','loc')
rownames(hdata_log_stats)<- c('mean','median','mode','threshold','sd')
hdata_log_stats<-as.table(hdata_log_stats)
hdata_log_th_branch<-hdata_log_mean[5]+hdata_log_sd[5]
hdata_log_th_loc<-hdata_log_mean[6]+hdata_log_sd[6]
hdata_log_thr<- matrix(c(hdata_log_th_ind, hdata_log_th_outd,hdata_log_th_acc,hdata_log_th_ts,hdata_log_th_branch, hdata_log_th_loc))
hdata_log_thr<-as.table(hdata_log_thr)
hdata_log_thr
hdata_log_stats<-matrix(c(hdata_log_mean, hdata_log_median, hdata_log_mode,  hdata_log_thr, hdata_log_sd),ncol = 6, byrow = TRUE)
colnames(hdata_log_stats)<-c('ind','outd','acc','ts','branch','loc')
rownames(hdata_log_stats)<- c('mean','median','mode','threshold','sd')
hdata_log_stats<-as.table(hdata_log_stats)
hdata_log_stats
write.csv(hdata_log_stats,"hdata_log_thrshold.csv")
hdata_exp_thr<-exp(hdata_log_thr)
#Now compare each metric with the threshold if metric is greater than the thr then that function has the bug otherwise not.
nRowsDf <- nrow(hdata)   #original data
for(i in 1:nRowsDf)
{
if(hdata[i,1]>hdata_exp_thr[1] || hdata[i,2]>hdata_exp_thr[2] || hdata[i,3]>hdata_exp_thr[3] ||
hdata[i,4]>hdata_exp_thr[4] || hdata[i,5]>hdata_exp_thr[5]|| hdata[i,6]>hdata_exp_thr[6])
{
hdata$bug[i]=2
}
else {
hdata$bug[i]=1
}
}
#View(hdata)
count(hdata$bug)
hdata$bug<-ifelse(hdata$bug>1,'YES','NO')
hdata$bug<- factor(hdata$bug, levels = c("NO","YES"))
count(hdata$bug)
write.csv(hdata,"hdata_labeled.csv")
hdata_melt<- melt(hdata, id.var = "bug")
hdata_melt$bug<-as.factor(hdata_melt$bug)
#View(hdata1_bug_melt) # pasting some rows of the melted data.frame
str(hdata_melt)
pdf("hdata_cluster_label_wise_bp.pdf")
p <- ggplot(data = hdata_melt, aes(x=variable, y=value)) + geom_boxplot(aes(fill=bug))
p + facet_wrap( ~ variable, scales="free")   #Boxplot as per requirment need to scale y axis
dev.off()
set.seed(11)
pdf("nbclust_horg_sil.pdf")
fviz_nbclust(horg, kmeans, method='silhouette')   #its working
dev.off()
pdf("nbclust_horg_gap.pdf")
fviz_nbclust(horg, kmeans, method='gap_stat')   #its working
dev.off()
pdf("nbclust_horg_wss.pdf")
dev.off()
fviz_nbclust(horg, kmeans, method='wss')   #its working
horg_std_obj <- preProcess(horg, method = c("medianImpute","center","scale")) #standardise mean-0 and sd-1, BoxCox,
horg_std_prpd<- predict(horg_std_obj, horg) #YeoJohnson producing skew ness minimum better than boxcox and log
basicStats(horg_std_prpd)
write.csv(horg_std_prpd,"horg_std_prpd_basicStats.csv")
set.seed(123)
ik=1
while (ik<=10) {
kmeans_horg_std_prpd_obj<-kmeans(horg_std_prpd,2,nstart = 25)
ik=ik+1
}
horg_std_prpd_dist<-dist(horg_std_prpd,method = "euclidean")^2
horg_std_prpd_sil=silhouette(kmeans_horg_std_prpd_obj$cluster,horg_std_prpd_dist)
pdf("horg_std_prpd_kmeans_sil_plot.pdf")
plot(horg_std_prpd_sil)
dev.off()
pdf("fviz_clust_horg_std_prpd.pdf")
fviz_cluster(kmeans_horg_std_prpd_obj,data = horg_std_prpd)
dev.off()
pdf("clustplot_horg_std_prpd.pdf")
clusplot(horg_std_prpd, kmeans_horg_std_prpd_obj$cluster, color=TRUE, shade = TRUE, label=2)
dev.off()
horg_std_prpd_bug<-cbind(horg_std_prpd,bug=kmeans_horg_std_prpd_obj$cluster)
count(horg_std_prpd_bug$bug)
horg_std_prpd_bug$bug<-ifelse(horg_std_prpd_bug$bug>1,'YES','NO')
horg_std_prpd_bug$bug<- factor(horg_std_prpd_bug$bug, levels = c("NO","YES"))
count(horg_std_prpd_bug$bug)
write.csv(horg_std_prpd_bug,"horg_std_prpd_bug.csv")
#horg_std_prpd_bug2<-read.csv("horg_std_prpd_bug2.csv")
hdata_cm<-confusionMatrix(factor(hdata$bug) , factor(horg_std_prpd_bug$bug))
hdata_cm
horg_basic_stats<-basicStats(horg)
write.csv(horg_basic_stats,'horg_basic_stats.csv')
horg_mean<- colMeans(horg)
horg_mean
horg_median<- apply(horg,2,median)  #2 is margin means col, sd is function
horg_median
horg_mode<- apply(horg,2,getmode)  #2 is margin means col, sd is function
horg_mode
horg_sd<- apply(horg,2,sd)  #2 is margin means col, sd is function
horg_sd
horg_stats<-matrix(c(horg_mean, horg_median, horg_mode,  hdata_exp_thr, horg_sd),ncol = 6, byrow = TRUE)
colnames(horg_stats)<-c('ind','outd','acc','ts','branch','loc')
rownames(horg_stats)<- c('mean','median','mode','threshold','sd')
horg_stats<-as.table(horg_stats)
horg_stats
write.csv(horg_stats,"horg_thrshold.csv")
horg_cla_thr<-as.matrix(horg_median)
for(i in 1:nRowsDf)
{
horg$k[i]<-sum((horg[i,1]>horg_cla_thr[1]),(horg[i,2]>horg_cla_thr[2]),(horg[i,3]>horg_cla_thr[3]),
(horg[i,4]>horg_cla_thr[4]),(horg[i,5]>horg_cla_thr[5]), (horg[i,6]>horg_cla_thr[6]))
}
for(i in 1:nRowsDf)
{
if(horg$k[i]>3)
{
horg$bug[i]=2
}
else {
horg$bug[i]=1
}
}
#View(horg)
count(horg$bug)
horg$bug<-ifelse(horg$bug>1,'YES','NO')
horg$bug<- factor(horg$bug, levels = c("NO","YES"))
count(horg$bug)
horg_cm<-confusionMatrix(factor(horg$bug) , factor(horg_std_prpd_bug$bug))
write.csv(horg,"horg_labeled.csv")
horg_cm
{
hdataorg$k[i]<-sum((hdataorg[i,1]>hdata_exp_thr[1]),(hdataorg[i,2]>hdata_exp_thr[2]),(hdataorg[i,3]>hdata_exp_thr[3]),
(hdataorg[i,4]>hdata_exp_thr[4]),(hdataorg[i,5]>hdata_exp_thr[5]), (hdataorg[i,6]>hdata_exp_thr[6]))
}
for(i in 1:nRowsDf)
for(i in 1:nRowsDf)
{
if(hdataorg$k[i]>3)
{
hdataorg$bug[i]=2
}
else {
hdataorg$bug[i]=1
}
}
#View(hdataorg)
count(hdataorg$bug)
hdataorg$bug<- factor(hdataorg$bug, levels = c("NO","YES"))
hdataorg$bug<-ifelse(hdataorg$bug>1,'YES','NO')
count(hdataorg$bug)
write.csv(hdataorg,"hdataorg_labeled.csv")
hdataorg_cm<-confusionMatrix(factor(hdataorg$bug) , factor(horg_std_prpd_bug$bug))
for(i in 1:nRowsDf)
{
hdataorg$k[i]<-sum((hdataorg[i,1]>hdata_exp_thr[1]),(hdataorg[i,2]>hdata_exp_thr[2]),(hdataorg[i,3]>hdata_exp_thr[3]),
(hdataorg[i,4]>hdata_exp_thr[4]),(hdataorg[i,5]>hdata_exp_thr[5]), (hdataorg[i,6]>hdata_exp_thr[6]))
}
for(i in 1:nRowsDf)
{
if(hdataorg$k[i]>3)
{
hdataorg$bug[i]=2
}
else {
hdataorg$bug[i]=1
}
}
#View(hdataorg)
count(hdataorg$bug)
hdataorg$bug<-ifelse(hdataorg$bug>1,'YES','NO')
hdataorg$bug<- factor(hdataorg$bug, levels = c("NO","YES"))
count(hdataorg$bug)
write.csv(hdataorg,"hdataorg_labeled.csv")
hdataorg_cm<-confusionMatrix(factor(hdataorg$bug) , factor(horg_std_prpd_bug$bug))
hdataorg_cm
hp1_org<-read.csv("ethereum.csv")
hp2_org<-read.csv("hburg.csv")
setwd("E:/Functional Paradigm/@implementation/fp_final_implemented/Round4_skew_cla_kmeans/sil_plot_optimal_k")
hp1_org<-read.csv("ethereum.csv")
hp2_org<-read.csv("hburg.csv")
hp3_org<-read.csv("mios.csv")
hp4_org<-read.csv("piet.csv")
set.seed(11)
png("nbclust_hp1_sil.png", width = 4, height = 4, units = 'in', res = 500)
fviz_nbclust(hp1_org, kmeans, method='silhouette')
library(cluster)    # clustering algorithms
library(factoextra)
fviz_nbclust(hp1_org, kmeans, method='silhouette')
png("nbclust_hp1_sil.png", width = 4, height = 4, units = 'in', res = 500)
fviz_nbclust(hp1_org, kmeans, method='silhouette')
dev.off()
png("nbclust_hp2_sil.png", width = 4, height = 4, units = 'in', res = 500)
fviz_nbclust(hp2_org, kmeans, method='silhouette')
dev.off()
png("nbclust_hp3_sil.png", width = 4, height = 4, units = 'in', res = 500)
dev.off()
fviz_nbclust(hp3_org, kmeans, method='silhouette')
png("nbclust_hp4_sil.png", width = 4, height = 4, units = 'in', res = 500)
fviz_nbclust(hp4_org, kmeans, method='silhouette')
dev.off()
png("nbclust_hp3_sil.png", width = 4, height = 4, units = 'in', res = 500)
fviz_nbclust(hp3_org, kmeans, method='silhouette')
dev.off()
png("nbclust_hp1_sil.png", width = 4, height = 4, units = 'in', res = 500)
fviz_nbclust(hp1_org, kmeans, method='silhouette')
dev.off()
source('E:/Functional Paradigm/@implementation/fp_final_implemented/Round4_skew_cla_kmeans/sil_plot_optimal_k/sil_plot_optimal_k.R', echo=TRUE)
setwd("E:/@Functional Paradigm/Applied Intelligence J Ppr/Write Paper/diagram_for TCL_fp_ppr/boxplot/sil_plot_optimal_k")
library(cluster)    # clustering algorithms
library(factoextra)
hp1_org<-read.csv("ethereum.csv")
hp2_org<-read.csv("hburg.csv")
hp3_org<-read.csv("mios.csv")
hp4_org<-read.csv("piet.csv")
set.seed(11)
pdf("nbclust_hp1_sil.pdf")
fviz_nbclust(hp1_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp2_sil.pdf")
fviz_nbclust(hp2_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp3_sil.png", width = 4, height = 4, units = 'in', res = 500)
fviz_nbclust(hp3_org, kmeans, method='silhouette')
pdf("nbclust_hp3_sil.pdf")
fviz_nbclust(hp3_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp4_sil.pdf")
fviz_nbclust(hp4_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp1_sil.pdf")
fviz_nbclust(hp1_org, kmeans, method='silhouette',width = 4, height = 4)
pdf("nbclust_hp1_sil.pdf",width =4, height = 3)
fviz_nbclust(hp1_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp1_sil.pdf",width =3, height = 2)
fviz_nbclust(hp1_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp1_sil.pdf",width =3.5, height = 2.5)
fviz_nbclust(hp1_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp1_sil.pdf",width =3.5, height = 2.5)
fviz_nbclust(hp1_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp2_sil.pdf",width =3.5, height = 2.5)
fviz_nbclust(hp2_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp3_sil.pdf",width =3.5, height = 2.5)
fviz_nbclust(hp3_org, kmeans, method='silhouette')
dev.off()
pdf("nbclust_hp4_sil.pdf",width =3.5, height = 2.5)
fviz_nbclust(hp4_org, kmeans, method='silhouette')
dev.off()
